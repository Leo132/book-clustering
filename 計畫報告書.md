# 期中報告書 - 我的閱讀柏克萊

# 1. 簡介與動機

本專題題目旨在改善使用者對於書籍的搜尋過程。普遍來說，大部分的網路書店都只提供書籍種類或出版社的選項讓使用者來篩選想要的書籍，但其數量通常都是偏多的，且僅提供以上或類似的功能。在眾多的書籍當中挑選想要的已經不容易了，篩選機制還需要使用者從繁雜的種類中選出符合所需要求的種類來完成，也沒有提供使用者其餘可用的資訊來加速篩選過程。

因此本專題題目為了優化篩選過程，利用分群演算法來分析其餘被忽略的書籍資訊。我們認為，書籍的頁數、價錢以及發行日期距今的時間都是可以被加以利用的，而採用分群演算法可以分析出這些額外資訊對於書籍之間的相似度，藉此讓使用者多一個面向來篩選書籍，達到優化篩選過程的效果。

另外還增加依據收藏書單的群類（cluster）分析來提升搜尋結果的推薦品質，讓使用者的搜尋體驗更好。

# 2. 相關文獻

## 2.1 爬蟲技術

網路爬蟲是一種自動化程式，用於在網路上檢索和收集訊息。它的歷史可以追溯到網路的早期階段。網路爬蟲的概念首次出現在20世紀90年代，當時網路開始普及。最早的爬蟲被用於建立搜索引擎索引，以幫助用戶查找網頁內容。

隨著技術的發展，爬蟲變得更加智慧化。網路爬蟲軟體開始使用更複雜的算法以識別網頁結構及跟隨超連結，以及避免重複訪問相同的頁面。

網路爬蟲的技術演進包括多執行緒處理、代理伺服器使用、標題解析和 JavaScript 處理，以適應現代網頁的複雜性。

在現代，有許多爬蟲工具可供選擇，每個都有其獨特的功能和優勢。

### Scrapy

Scrapy 是一個用於 Python 的強大爬蟲框架，它提供了一個高度可定制的環境，可以用於爬取和處理網頁數據。它支持異步請求和允許用戶定義複雜的爬蟲規則。

### Beautiful Soup

Beautiful Soup 是一個 Python 函式庫，專為解析 HTML 和 XML 文件而設計。它使得解析網頁數據變得容易，並提供了用於檢索和操作 DOM 的方法。

### Apache Nutch

Apache Nutch 是一個開源的網路爬蟲和搜索引擎軟體。它支持大規模的數據抓取和分佈式爬蟲操作，非常適合用於構建搜索引擎。

網路爬蟲是搜索引擎的核心組件，用於收集並索引網頁，以供用戶進行搜索。Google、Bing 和 Yahoo 等搜索引擎使用爬蟲技術。

以下為一些相關的應用：

- **價格比較和競爭情報**：零售商和企業使用爬蟲來監控競爭對手的價格、產品訊息和庫存情況，以制定定價策略。
- **新聞聚合**：許多新聞網站和應用程式使用爬蟲來自動收集新聞故事，並將它們組織成新聞聚合。
- **內容議題追踪**：爬蟲也用於追蹤特定主題或關鍵字的內容，以用於市場研究、社交媒體監控和趨勢分析。
- **研究和學術用途**：學術研究人員使用爬蟲來收集數據，以進行社會科學研究、自然語言處理和其他學術領域的研究。

## 2.2 文字斷詞

文字斷詞是自然語言處理領域中的一個基本任務，旨在將連續的文本序列切割成有意義的詞彙。早期的文字斷詞方法主要基於規則和字典，這些方法通常根據特定語言的結構和規則進行操作。這些規則可能包括空格、標點符號和其他語言特定的分隔符。

隨著統計自然語言處理的興起，出現了一些基於統計模型的文字斷詞方法，如隱藏式馬可夫模型（HMM）和最大熵模型。這些方法利用統計訊息和上下文來進行斷詞。

近年來，隨著深度學習技術的發展，深度學習模型如循環神經網路（RNN）和長短期記憶（LSTM）等被應用於文字斷詞，使得模型更能理解上下文和語境。

在文字斷詞的方法和模型方面，有多種技術可供選擇。

### 規則基礎方法

這種方法基於事先定義的規則和字典，例如長詞優先法（MM）、最大簡約法（MP）等。它們適用於一些具有明確詞彙結構的語言。

### 統計方法

使用統計模型，如隱藏式馬可夫模型（HMM）和最大熵模型，通常基於訓練數據的統計分佈來預測單詞邊界。這些方法對於語言的統計特性有一定的適應性。

### 深度學習方法

近年來，基於深度學習的模型，如循環神經網路（RNN）、長短期記憶（LSTM）和 Transformer 模型等，通常能夠更好地捕捉上下文訊息，提高斷詞的準確性。

文字斷詞技術在現代的相關應用：

- **機器翻譯**：在機器翻譯中，準確的文字斷詞是關鍵步驟之一，能夠影響翻譯系統的性能。
- **搜索引擎**：搜索引擎需要對網頁進行斷詞以建立索引，這有助於提高搜索的效率和精確度。
- **自然語言處理應用**：在自然語言處理任務中，如命名實體識別、文本分類和情感分析等，文字斷詞都是前處理的重要步驟。
- **社交媒體分析**：在社交媒體上，文字斷詞可用於分析用戶的評論、回應和情感，以洞察用戶行為和趨勢。
- **智慧助理和語音辨識**：對語音轉文本進行文字斷詞有助於提高語音辨識的精確性，同時也在智慧助理中應用廣泛。

## 2.3 分群演算法

分群演算法是一種機器學習和數據分析技術，用於將數據集中的對象分為不同的群類，每個群類內的對象彼此相似。

分群的概念可以追溯到統計學和數學中的集群分析，而真正的分群演算法是在計算機科學領域開始得到廣泛應用，早期的算法包括 K 均值和層次式分群。

隨著數據科學和機器學習的發展，分群演算法變得更加強大和多樣化。現代的演算法使用更高級的數學技術，例如非監督學習和深度學習，以改進分群的效果。

在現代，有多種分群演算法可供選擇，每個都有其獨特的特點和應用。

### K 平均演算法

K 平均演算法是一種基於中心的分群方法，它將數據分為 K 個群類，每個群類由其質心表示。它是一個簡單而有效的分群方法，通常用於數據壓縮和分析。

### 層次式分群

層次式分群是一種將數據分為多個層次結構的方法。它可以形成一個樹狀結構，顯示不同層次的相似性。這種分群方法通常用於數據可視化和分析。

### DBSCAN

DBSCAN 是一種基於密度的分群方法，它可以識別不同形狀和大小的群類。它對噪音數據具有較高的容忍度，並可應用於各種應用中。

以下為一些相關的應用：

- **醫學影像分析**：分群演算法可用於分類和分群醫學影像，幫助醫生診斷疾病，例如腫瘤檢測和影像分類。
- **社交網路分析**：在社交媒體和網路中，分群演算法用於識別用戶社交關係和興趣，以個性化推薦和社交網路分析。
- **市場分析和用戶行為**：分群演算法可幫助企業分析市場和用戶行為，以定義目標市場和制定針對性的營銷策略。
- **自然語言處理**：在文本分析中，分群演算法可用於主題建模和文件分類，以識別相關文檔。
- **環境監測和感測網路**：在物聯網領域，分群演算法用於分析和監測環境數據，例如氣象數據和感測數據。

# 3. 系統功能

本系統是為了提升使用者的篩選、搜尋的速度及品質，因此會需要分析並標記各書籍的所屬群類以及基本的書籍類別篩選與關鍵字搜尋功能，最後還有根據收藏書單來做書籍推薦的機制，以下將會詳細說明。

## 3.1 使用者介面

介面設計大致分為登入、搜尋收藏書單等頁面。登入頁面主要是讓使用者能夠註冊帳號並登入，而主要的功能都在搜尋頁面，包含搜尋書籍、篩選書籍類別以及顯示查詢結果，最後收藏書單的頁面類似於搜尋頁面的查詢解果，用於查看使用者收藏的書籍。

## 3.2 基本功能

本系統同樣提供與網路書店相似的搜尋功能，分別是書籍種類的篩選以及關鍵字搜尋等，並在此基礎之上進一步的優化搜尋體驗。

### 書籍種類篩選

首先，使用者可以透過與一般網路書店相似的種類篩選功能來過濾一些不相關的書籍，主要是利用選單的方式讓使用者可以勾選多種書籍類別，讓搜尋結果只包含勾選的種類，但可勾選的種類僅限於儲存在資料庫中之書籍的種類，因受限於爬取的資料量，所以無法涵蓋網路書店中的所有種類。

### 關鍵字搜尋

接著，本系統還提供了關鍵字的搜尋功能，用於對應若使用者已知某主題的名稱，亦或是某書或系列的部分名稱，則可以直接透過此功能來直接查詢，但若僅單純的使用關鍵字來查詢，會使搜尋的條件過於嚴苛，導致過度依靠使用者所輸入的關鍵字。因此，我們效仿網路書店的搜尋功能，將使用者的輸入先經過斷詞處理，再根據原本的關鍵字以及斷詞結果來作為關鍵字搜尋的輸入，藉此來減緩過度依靠使用者輸入的問題。

## 3.3 書籍資料分析

將存於資料庫的書籍資訊做群類的分析為本系統的主軸，我們所選用的是常見的 K 平均值演算法，並利用被忽略的書籍資訊來進一步的去分析書籍間的關係，再將分析後的群類結果作為搜尋頁面的初始畫面，讓使用者可以選擇要採用分群的結果來尋找想要的書籍，或是使用關鍵字搜尋來直接地從資料庫中尋找目標書籍，當然兩者都可以搭配書籍種類篩選功能，以下就來詳細的說明我們的做法。

首先，我們發現書籍所提供的資訊有部分是屬於數字類的，像是頁數、價格以及出版距今時間等，且這些資訊都是沒有被考慮為篩選依據的。因此，我們採用 K 平均演算法對這些資訊做分群，舉例來說，頁數較少的書籍可能會被標記為某一個群類，而價格較高的書籍可能也會被標記為某個群類，這樣以此類推，且這些群類不只是考慮各別單一的書籍資訊，而是聯合三種資訊一併分析，所以分群的結果可能會有一個群類的特徵是頁數少、價格低且發行日期久遠，或是頁數較多、價格偏高且發行日期較新等，利用這些已分析完的群類標記，在搜尋的初始畫面中直接呈現給使用者，讓使用者可以透過檢視各群類的中心，我們稱為虛擬代表書籍，的資訊來選出與預想書籍較相近的群類，再從此群類中使用書籍種類篩選、關鍵字搜尋或是兩者的搭配來針對此群類做查詢。

## 3.4 基於分群的推薦機制

因搜尋結果的數量是不可測的，可能會有大量的書籍符合搜尋條件讓使用者面臨相同的問題，也可能僅有少量的書籍符合條件，甚至完全沒有符合條件的書籍，所以這是需要被解決的問題。但對於書籍量過少的問題牽涉到資料庫所存有的書籍量，因此本系統僅提出基於分群的推薦機制來解決當書籍量過大時，如何從中挑選較適合來推薦給使用者。

同樣的，我們採用 K 平均演算法來分析書籍資訊，並利用此結果作為依據來推薦搜尋結果中的書籍，但有別於分析存於資料庫中的所有書籍，我們的推薦機制所分析的是使用者獨立的收藏書單。我們認為，收藏書單是含有使用者喜好的，因為一書籍若被使用者收藏，表示此書籍是使用者從搜尋結果中的眾多書籍中挑選出來感興趣的，因此分析收藏書單中的潛在群類，理因可得出使用者所喜愛的書籍群類之特徵，也就是使用者愛好的虛擬代表書籍，並根據這些虛擬代表書籍來計算出搜尋結果中各書籍的推薦分數。

將我們提出的推薦機制公式化後得出

$$
\begin{align}
&w_i=\frac{|B_i|}{{\textstyle\sum}^n_{j=1}|B_j|},&&B_i\in\{B_1,B_2,\dots,B_n\}\\
&\text{sim}(a, b)=\min\bigg(\frac{1}{d(a, b)+\epsilon},\  \alpha\bigg),&&\epsilon,\ \alpha\in\mathbb R\\
&\text{score}=\displaystyle\sum_{i=1}^nw_i\cdot \text{sim}(x, v_i),&&x\in X,\ v_i\in V
\end{align}
$$

其中， $B$ 為各群類的書籍資訊向量集合， $X$ 為搜尋結果的書籍資訊向量集合， $V$ 為各群類的虛擬代表書籍向量集合， $w$ 為各群類的重要性， $d()$ 為兩向量的距離， $\text{sim}()$ 為兩書籍資訊向量的相似度，且以 $\alpha$ 來規範其最大值。

因此搜尋結果中的每本書籍都會有對應的推薦分數，再利用此分數對搜尋結果進行排序，讓使用者最先看到的就是最為推薦的書籍。

# 4. 資料庫 ERD

為了實現本系統所提供的功能，我們首先列出了主要的書籍實體，以及圍繞於主要實體的四個實體，分別為作者、出版社、其群類和使用者，各別儲存與書籍有關之實體的屬性，其中使用者還擁有一個收藏書單弱實體，用於儲存某使用者所收藏的書籍，而實體間的關係就如下圖所示。

![ERD](./data/img/ERD.jpg)

書籍以及出版社、作者的屬性都是網路書店所提供的，而書籍是取自網路書店所排出的本月暢銷榜，使用者的資訊以及對應的收藏書單則是透過註冊功能來建立，最後的群類是直接將已爬取的書籍資料做分群後，將各群類的統計資訊，也就是虛擬代表書籍資訊，存回資料庫中。

# 5. 後續進度規劃

後續會依序實作資料庫的設計、系統的功能以及效果測試等，如果有需要也會將未考慮周全的部分進行優化。

## 5.1 資料庫實作

我們會根據目前規畫好的 ERD 來設計資料庫。具體來說，我們會先將初版的 ERD 轉成關聯表，並把關係轉成外來鍵，過程中可能會遇到設計不佳的狀況，因此再回來修改 ERD 並同樣地轉換成關聯表及外來鍵，如此反覆的優化來完成最終的實作。

## 5.2 系統功能實作

我們預期會使用 Python 以 Tkinter 來實作使用者介面，而分群演算法的實作則會直接採用 scikit-learn 的模組，斷詞的模型預計會使用由中研院提供的 ckiptagger 模型，

## 5.3 功能測試

此階段主要是先測試功能是否有正常執行，再來就是透過組員給出的使用體驗來測試系統的功能，檢視成果是否符合預期，大部分都是人為的測試。
